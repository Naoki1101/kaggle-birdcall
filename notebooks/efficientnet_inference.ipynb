{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import yaml\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "import librosa\n",
    "import librosa.display\n",
    "import audioread\n",
    "import soundfile as sf\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import albumentations as album\n",
    "\n",
    "sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master')\n",
    "from efficientnet_pytorch import model as enet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EasyDict(dict):\n",
    "    \"\"\"\n",
    "    Get attributes\n",
    "    >>> d = EasyDict({'foo':3})\n",
    "    >>> d['foo']\n",
    "    3\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    AttributeError: 'EasyDict' object has no attribute 'bar'\n",
    "    Works recursively\n",
    "    >>> d = EasyDict({'foo':3, 'bar':{'x':1, 'y':2}})\n",
    "    >>> isinstance(d.bar, dict)\n",
    "    True\n",
    "    >>> d.bar.x\n",
    "    1\n",
    "    Bullet-proof\n",
    "    >>> EasyDict({})\n",
    "    {}\n",
    "    >>> EasyDict(d={})\n",
    "    {}\n",
    "    >>> EasyDict(None)\n",
    "    {}\n",
    "    >>> d = {'a': 1}\n",
    "    >>> EasyDict(**d)\n",
    "    {'a': 1}\n",
    "    Set attributes\n",
    "    >>> d = EasyDict()\n",
    "    >>> d.foo = 3\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar = {'prop': 'value'}\n",
    "    >>> d.bar.prop\n",
    "    'value'\n",
    "    >>> d\n",
    "    {'foo': 3, 'bar': {'prop': 'value'}}\n",
    "    >>> d.bar.prop = 'newer'\n",
    "    >>> d.bar.prop\n",
    "    'newer'\n",
    "    Values extraction\n",
    "    >>> d = EasyDict({'foo':0, 'bar':[{'x':1, 'y':2}, {'x':3, 'y':4}]})\n",
    "    >>> isinstance(d.bar, list)\n",
    "    True\n",
    "    >>> from operator import attrgetter\n",
    "    >>> map(attrgetter('x'), d.bar)\n",
    "    [1, 3]\n",
    "    >>> map(attrgetter('y'), d.bar)\n",
    "    [2, 4]\n",
    "    >>> d = EasyDict()\n",
    "    >>> d.keys()\n",
    "    []\n",
    "    >>> d = EasyDict(foo=3, bar=dict(x=1, y=2))\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar.x\n",
    "    1\n",
    "    Still like a dict though\n",
    "    >>> o = EasyDict({'clean':True})\n",
    "    >>> o.items()\n",
    "    [('clean', True)]\n",
    "    And like a class\n",
    "    >>> class Flower(EasyDict):\n",
    "    ...     power = 1\n",
    "    ...\n",
    "    >>> f = Flower()\n",
    "    >>> f.power\n",
    "    1\n",
    "    >>> f = Flower({'height': 12})\n",
    "    >>> f.height\n",
    "    12\n",
    "    >>> f['power']\n",
    "    1\n",
    "    >>> sorted(f.keys())\n",
    "    ['height', 'power']\n",
    "    update and pop items\n",
    "    >>> d = EasyDict(a=1, b='2')\n",
    "    >>> e = EasyDict(c=3.0, a=9.0)\n",
    "    >>> d.update(e)\n",
    "    >>> d.c\n",
    "    3.0\n",
    "    >>> d['c']\n",
    "    3.0\n",
    "    >>> d.get('c')\n",
    "    3.0\n",
    "    >>> d.update(a=4, b=4)\n",
    "    >>> d.b\n",
    "    4\n",
    "    >>> d.pop('a')\n",
    "    4\n",
    "    >>> d.a\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    AttributeError: 'EasyDict' object has no attribute 'a'\n",
    "    \"\"\"\n",
    "    def __init__(self, d=None, **kwargs):\n",
    "        if d is None:\n",
    "            d = {}\n",
    "        if kwargs:\n",
    "            d.update(**kwargs)\n",
    "        for k, v in d.items():\n",
    "            setattr(self, k, v)\n",
    "        # Class attributes\n",
    "        for k in self.__class__.__dict__.keys():\n",
    "            if not (k.startswith('__') and k.endswith('__')) and not k in ('update', 'pop'):\n",
    "                setattr(self, k, getattr(self, k))\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            value = [self.__class__(x)\n",
    "                     if isinstance(x, dict) else x for x in value]\n",
    "        elif isinstance(value, dict) and not isinstance(value, self.__class__):\n",
    "            value = self.__class__(value)\n",
    "        super(EasyDict, self).__setattr__(name, value)\n",
    "        super(EasyDict, self).__setitem__(name, value)\n",
    "\n",
    "    __setitem__ = __setattr__\n",
    "\n",
    "    def update(self, e=None, **f):\n",
    "        d = e or dict()\n",
    "        d.update(f)\n",
    "        for k in d:\n",
    "            setattr(self, k, d[k])\n",
    "\n",
    "    def pop(self, k, d=None):\n",
    "        delattr(self, k)\n",
    "        return super(EasyDict, self).pop(k, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_code = {\n",
    "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
    "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
    "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
    "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
    "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
    "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
    "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
    "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
    "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
    "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
    "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n",
    "    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n",
    "    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n",
    "    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n",
    "    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n",
    "    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n",
    "    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n",
    "    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n",
    "    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n",
    "    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n",
    "    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n",
    "    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n",
    "    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n",
    "    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n",
    "    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n",
    "    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n",
    "    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n",
    "    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n",
    "    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n",
    "    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n",
    "    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n",
    "    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n",
    "    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n",
    "    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n",
    "    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n",
    "    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n",
    "    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n",
    "    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n",
    "    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n",
    "    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n",
    "    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n",
    "    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n",
    "    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n",
    "    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n",
    "    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n",
    "    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n",
    "    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n",
    "    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n",
    "    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n",
    "    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n",
    "    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n",
    "    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n",
    "    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n",
    "}\n",
    "\n",
    "inv_bird_code = {v: k for k, v in bird_code.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X: np.ndarray,\n",
    "                  mean=None,\n",
    "                  std=None,\n",
    "                  norm_max=None,\n",
    "                  norm_min=None,\n",
    "                  eps=1e-6):\n",
    "    \"\"\"\n",
    "    Code from https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data\n",
    "    \"\"\"\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, cfg, clip):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.clip = clip\n",
    "        self.transforms = get_transforms(self.cfg)\n",
    "        self.is_train = cfg.is_train\n",
    "        self.sites = df['site'].values\n",
    "        self.row_ids = df['row_id'].values\n",
    "        self.seconds = df['seconds'].values\n",
    "        self.melspectrogram_parameters = {'n_mels': 128,\n",
    "                                                                        'fmin': 20,\n",
    "                                                                        'fmax': 16_000}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.row_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        SR = 32_000\n",
    "        site = self.sites[idx]\n",
    "        row_id = self.row_ids[idx]\n",
    "        \n",
    "        if site == 'site_3':\n",
    "            y = self.clip.astype(np.float32)\n",
    "            len_y = len(y)\n",
    "            start = 0\n",
    "            end = SR * 5\n",
    "            images = []\n",
    "            while len_y > start:\n",
    "                y_batch = y[start: end].astype(np.float32)\n",
    "                if len(y_batch) != (SR * 5):\n",
    "                    break\n",
    "                start = end\n",
    "                end += SR * 5\n",
    "                \n",
    "                melspec = librosa.feature.melspectrogram(y_batch,\n",
    "                                                                                           sr=SR,\n",
    "                                                                                           **self.melspectrogram_parameters)\n",
    "                melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "                image = mono_to_color(melspec)\n",
    "                \n",
    "                if self.transforms:\n",
    "                    image = self.transforms(image=image)['image']\n",
    "\n",
    "                image = cv2.resize(image, (self.cfg.img_size.height, self.cfg.img_size.width))\n",
    "                image = image.transpose(2, 0, 1).astype(np.float32)\n",
    "                image = (image / 255.0).astype(np.float32)\n",
    "                images.append(image)\n",
    "            \n",
    "            images = np.asarray(images)\n",
    "            return images, row_id, site\n",
    "        else:\n",
    "            end_seconds = int(self.seconds[idx])\n",
    "            start_seconds = int(end_seconds - 5)\n",
    "            \n",
    "            start_index = SR * start_seconds\n",
    "            end_index = SR * end_seconds\n",
    "            \n",
    "            y = self.clip[start_index:end_index].astype(np.float32)\n",
    "\n",
    "            melspec = librosa.feature.melspectrogram(y, sr=SR, **self.melspectrogram_parameters)\n",
    "            melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "            \n",
    "            image = mono_to_color(melspec)\n",
    "\n",
    "            if self.transforms:\n",
    "                image = self.transforms(image=image)['image']\n",
    "\n",
    "            image = cv2.resize(image, (self.cfg.img_size.height, self.cfg.img_size.width))\n",
    "            image = image.transpose(2, 0, 1).astype(np.float32)\n",
    "            image = (image / 255.0).astype(np.float32)\n",
    "            \n",
    "            return image, row_id, site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/bengaliai-cv19/discussion/123432\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "    \n",
    "    \n",
    "layer_encoder = {\n",
    "    'GeM': GeM,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cel = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        return self.cel(yhat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _efficientnet(model_name, pretrained):\n",
    "    if pretrained:\n",
    "        model = enet.EfficientNet.from_pretrained(model_name, advprop=True)\n",
    "    else:\n",
    "        model = enet.EfficientNet.from_name(model_name)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def efficientnet_b0(model_name='efficientnet-b0', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b1(model_name='efficientnet-b1', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b2(model_name='efficientnet-b2', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b3(model_name='efficientnet-b3', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b4(model_name='efficientnet-b4', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b5(model_name='efficientnet-b5', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b6(model_name='efficientnet-b6', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b7(model_name='efficientnet-b7', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = {\n",
    "    model_encoder = {\n",
    "    'efficientnet_b0': efficientnet_b0,\n",
    "    'efficientnet_b1': efficientnet_b1,\n",
    "    'efficientnet_b2': efficientnet_b2,\n",
    "    'efficientnet_b3': efficientnet_b3,\n",
    "    'efficientnet_b4': efficientnet_b4,\n",
    "    'efficientnet_b5': efficientnet_b5,\n",
    "    'efficientnet_b6': efficientnet_b6,\n",
    "    'efficientnet_b7': efficientnet_b7,\n",
    "}\n",
    "}\n",
    "\n",
    "\n",
    "def set_channels(child, cfg):\n",
    "    if cfg.model.n_channels < 3:\n",
    "        child_weight = child.weight.data[:, :cfg.model.n_channels, :, :]\n",
    "    else:\n",
    "        child_weight = torch.cat([child.weight.data[:, :, :, :], child.weight.data[:, :int(cfg.model.n_channels - 3), :, :]], dim=1)\n",
    "    setattr(child, 'in_channels', cfg.model.n_channels)\n",
    "\n",
    "    if cfg.model.pretrained:\n",
    "        setattr(child.weight, 'data', child_weight)\n",
    "\n",
    "\n",
    "def replace_channels(model, cfg):\n",
    "    if cfg.model.name.startswith('densenet'):\n",
    "        set_channels(model.features[0], cfg)\n",
    "    elif cfg.model.name.startswith('efficientnet'):\n",
    "        set_channels(model._conv_stem, cfg)\n",
    "    elif cfg.model.name.startswith('mobilenet'):\n",
    "        set_channels(model.features[0][0], cfg)\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        set_channels(model.layer0.conv1, cfg)\n",
    "    elif cfg.model.name.startswith('resnet') or cfg.model.name.startswith('resnex') or cfg.model.name.startswith('wide_resnet'):\n",
    "        set_channels(model.conv1, cfg)\n",
    "    elif cfg.model.name.startswith('resnest'):\n",
    "        set_channels(model.conv1[0], cfg)\n",
    "    elif cfg.model.name.startswith('ghostnet'):\n",
    "        set_channels(model.features[0][0], cfg)\n",
    "\n",
    "\n",
    "def get_head(cfg):\n",
    "    head_modules = []\n",
    "    \n",
    "    for m in cfg.values():\n",
    "        if hasattr(nn, m['name']):\n",
    "            module = getattr(nn, m['name'])(**m['params'])\n",
    "        elif m['name'] in layer_encoder:\n",
    "            module = layer_encoder[m['name']](**m['params'])\n",
    "        head_modules.append(module)\n",
    "\n",
    "    head_modules = nn.Sequential(*head_modules)\n",
    "    \n",
    "    return head_modules\n",
    "\n",
    "\n",
    "def replace_fc(model, cfg):\n",
    "    if cfg.model.metric:\n",
    "        classes = 1000\n",
    "    else:\n",
    "        classes = cfg.model.n_classes\n",
    "\n",
    "    if cfg.model.name.startswith('densenet'):\n",
    "        model.classifier = get_head(cfg.model.head)\n",
    "    elif cfg.model.name.startswith('efficientnet'):\n",
    "        model._fc = get_head(cfg.model.head)\n",
    "    elif cfg.model.name.startswith('mobilenet'):\n",
    "        model.classifier[1] = get_head(cfg.model.head)\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        model.last_linear = get_head(cfg.model.head)\n",
    "    elif (cfg.model.name.startswith('resnet') or\n",
    "          cfg.model.name.startswith('resnex') or\n",
    "          cfg.model.name.startswith('wide_resnet') or\n",
    "          cfg.model.name.startswith('resnest')):\n",
    "        model.fc = get_head(cfg.model.head)\n",
    "    elif cfg.model.name.startswith('ghostnet'):\n",
    "        model.classifier = get_head(cfg.model.head)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def replace_pool(model, cfg):\n",
    "    avgpool = layer_encoder[cfg.model.avgpool.name](**cfg.model.avgpool.params)\n",
    "    if cfg.model.name.startswith('efficientnet'):\n",
    "        model._avg_pooling = avgpool\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        model.avg_pool = avgpool\n",
    "    elif (cfg.model.name.startswith('resnet') or\n",
    "          cfg.model.name.startswith('resnex') or\n",
    "          cfg.model.name.startswith('wide_resnet') or\n",
    "          cfg.model.name.startswith('resnest')):\n",
    "        model.avgpool = avgpool\n",
    "    elif cfg.model.name.startswith('ghostnet'):\n",
    "        model.squeeze[-1] = avgpool\n",
    "    return model\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.base_model = model_encoder[cfg.model.name](pretrained=False)\n",
    "        if cfg.model.n_channels != 3:\n",
    "            replace_channels(self.base_model, cfg)\n",
    "        if cfg.model.avgpool:\n",
    "            self.base_model = replace_pool(self.base_model, cfg)\n",
    "        self.model = replace_fc(self.base_model, cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(cfg, is_train=True):\n",
    "    model = CustomModel(cfg)\n",
    "\n",
    "    if cfg.model.multi_gpu and is_train:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_loss(cfg):\n",
    "    loss_ = getattr(loss, cfg.loss.name)(**cfg.loss.params)\n",
    "    return loss_\n",
    "\n",
    "\n",
    "def get_dataloader(df, cfg, clip):\n",
    "    dataset = CustomDataset(df, cfg, clip)\n",
    "    loader = DataLoader(dataset, **cfg.loader)\n",
    "    return loader\n",
    "\n",
    "\n",
    "def get_optim(cfg, parameters):\n",
    "    optim = getattr(torch.optim, cfg.optimizer.name)(params=parameters, **cfg.optimizer.params)\n",
    "    return optim\n",
    "\n",
    "\n",
    "def get_scheduler(cfg, optimizer):\n",
    "    if cfg.scheduler.name == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            **cfg.scheduler.params,\n",
    "        )\n",
    "    else:\n",
    "        scheduler = getattr(torch.optim.lr_scheduler, cfg.scheduler.name)(\n",
    "            optimizer,\n",
    "            **cfg.scheduler.params,\n",
    "        )\n",
    "    return scheduler\n",
    "\n",
    "\n",
    "def get_transforms(cfg):\n",
    "    def get_object(transform):\n",
    "        if hasattr(album, transform.name):\n",
    "            return getattr(album, transform.name)\n",
    "        elif hasattr(custom_album, transform.name):\n",
    "            return getattr(custom_album, transform.name)\n",
    "        else:\n",
    "            return eval(transform.name)\n",
    "    if cfg.transforms:\n",
    "        transforms = [get_object(transform)(**transform.params) for name, transform in cfg.transforms.items()]\n",
    "        return album.Compose(transforms)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_fold(cfg, df, target):\n",
    "    df_ = df.copy()\n",
    "    target_columns = target.columns[0]\n",
    "    df_[target_columns] = target[target_columns].values\n",
    "\n",
    "    fold_df = pd.DataFrame(index=range(len(df_)))\n",
    "\n",
    "    if len(cfg.weight) == 1:\n",
    "        weight_list = [cfg.weight[0] for i in range(cfg.params.n_splits)]\n",
    "    else:\n",
    "        weight_list = cfg.weight\n",
    "\n",
    "    fold = getattr(validation, cfg.name)(cfg)\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(fold.split(df_)):\n",
    "        fold_df[f'fold_{fold_}'] = 0\n",
    "        fold_df.loc[val_idx, f'fold_{fold_}'] = weight_list[fold_]\n",
    "    \n",
    "    return fold_df\n",
    "\n",
    "\n",
    "def get_metrics(cfg):\n",
    "    evaluator = getattr(metrics, cfg)\n",
    "    return evaluator\n",
    "\n",
    "\n",
    "def fill_dropped(dropped_array, drop_idx):\n",
    "    filled_array = np.zeros(len(dropped_array) + len(drop_idx))\n",
    "    idx_array = np.arange(len(filled_array))\n",
    "    use_idx = np.delete(idx_array, drop_idx)\n",
    "    filled_array[use_idx] = dropped_array\n",
    "    return filled_array\n",
    "\n",
    "\n",
    "def get_drop_idx(cfg):\n",
    "    drop_idx_list = []\n",
    "    for drop_name in cfg:\n",
    "        drop_idx = np.load(f'../pickle/{drop_name}.npy')\n",
    "        drop_idx_list.append(drop_idx)\n",
    "    all_drop_idx = np.unique(np.concatenate(drop_idx_list))\n",
    "    return all_drop_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def prediction_for_clip(test_df, clip, model, cfg, threshold=0.5):\n",
    "    test_loader = get_dataloader(test_df, cfg.data.test, clip)\n",
    "    \n",
    "    model.eval()\n",
    "    prediction_dict = {}\n",
    "    for i, (image, row_id, site) in enumerate(test_loader):\n",
    "        site = site[0]\n",
    "        row_id = row_id[0]\n",
    "\n",
    "        if site in {\"site_1\", \"site_2\"}:\n",
    "            image = Variable(image).to(device)\n",
    "            with torch.no_grad():\n",
    "                preds = F.sigmoid(model(image.float()))\n",
    "                preds = preds.cpu().detach().numpy().reshape(-1)\n",
    "            events = preds >= threshold\n",
    "            labels = np.argwhere(events).reshape(-1).tolist()\n",
    "\n",
    "        else:\n",
    "            image = image.squeeze(0)\n",
    "            batch_size = 16\n",
    "            whole_size = image.size(0)\n",
    "            if whole_size % batch_size == 0:\n",
    "                n_iter = whole_size // batch_size\n",
    "            else:\n",
    "                n_iter = whole_size // batch_size + 1\n",
    "\n",
    "            all_events = set()\n",
    "            for batch_i in range(n_iter):\n",
    "                batch = image[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "                if batch.ndim == 3:\n",
    "                    batch = batch.unsqueeze(0)\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    preds = F.sigmoid(model(batch))\n",
    "                    preds = preds.cpu().detach().numpy()\n",
    "\n",
    "                events = preds >= threshold\n",
    "                for i in range(len(events)):\n",
    "                    event = events[i, :]\n",
    "                    labels = np.argwhere(event).reshape(-1).tolist()\n",
    "                    for label in labels:\n",
    "                        all_events.add(label)\n",
    "                \n",
    "                labels = list(all_events)\n",
    "        if len(labels) == 0:\n",
    "            prediction_dict[row_id] = 'nocall'\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: inv_bird_code[x], labels))\n",
    "            label_string = ' '.join(labels_str_list)\n",
    "            prediction_dict[row_id] = label_string\n",
    "    return prediction_dict\n",
    "\n",
    "\n",
    "def prediction(test_df, test_audio_dir, target_sr, cfg, log_path):\n",
    "    model = get_model(cfg, is_train=False).to(device)\n",
    "    model.load_state_dict(torch.load(f'{str(log_path)}/weight_best_0.pt'))\n",
    "    \n",
    "    unique_audio_id = test_df['audio_id'].unique()\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "    for audio_id in unique_audio_id:\n",
    "        clip, _ = librosa.load(str(test_audio_dir / f'{audio_id}.mp3'),\n",
    "                                            sr=target_sr,\n",
    "                                            mono=True,\n",
    "                                            res_type=\"kaiser_fast\")\n",
    "        test_df_for_audio_id = test_df[test_df['audio_id'] == audio_id]\n",
    "        prediction_dict = prediction_for_clip(test_df_for_audio_id,\n",
    "                                                                         clip=clip,\n",
    "                                                                         model=model,\n",
    "                                                                         cfg=cfg,\n",
    "                                                                         threshold=0.7)\n",
    "        row_id = list(prediction_dict.keys())\n",
    "        birds = list(prediction_dict.values())\n",
    "        prediction_df = pd.DataFrame({\n",
    "                \"row_id\": row_id,\n",
    "                \"birds\": birds\n",
    "        })\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    \n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/kaggle/input/birdsong-recognition/')\n",
    "data_dir = root / 'test_audio'\n",
    "save_resample_dir = Path('/kaggle/test_audio_resample')\n",
    "save_mel_dir = Path('/kaggle/test_audio_mel')\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    test_df = pd.read_csv('/kaggle/input/birdcall-check/test.csv')\n",
    "    data_dir = Path('/kaggle/input/birdcall-check/test_audio')\n",
    "else:\n",
    "    test_df = pd.read_csv(root / 'test.csv')\n",
    "    \n",
    "test_audio_infos = test_df[['audio_id', 'site', 'seconds']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = Path(glob.glob('/kaggle/input/sub-*')[0])\n",
    "\n",
    "with open(log_path / 'config.yml', 'r') as yf:\n",
    "    cfg = EasyDict(yaml.safe_load(yf))\n",
    "\n",
    "TARGET_SR = 32000\n",
    "\n",
    "sub_df = prediction(test_df=test_df, \n",
    "                                   test_audio_dir=data_dir, \n",
    "                                   target_sr=TARGET_SR,\n",
    "                                   cfg=cfg,\n",
    "                                   log_path=log_path)\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "sub_df['birds'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
