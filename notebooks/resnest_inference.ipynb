{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import yaml\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "import librosa\n",
    "import librosa.display\n",
    "import audioread\n",
    "import soundfile as sf\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "import albumentations as album"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EasyDict(dict):\n",
    "    \"\"\"\n",
    "    Get attributes\n",
    "    >>> d = EasyDict({'foo':3})\n",
    "    >>> d['foo']\n",
    "    3\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    AttributeError: 'EasyDict' object has no attribute 'bar'\n",
    "    Works recursively\n",
    "    >>> d = EasyDict({'foo':3, 'bar':{'x':1, 'y':2}})\n",
    "    >>> isinstance(d.bar, dict)\n",
    "    True\n",
    "    >>> d.bar.x\n",
    "    1\n",
    "    Bullet-proof\n",
    "    >>> EasyDict({})\n",
    "    {}\n",
    "    >>> EasyDict(d={})\n",
    "    {}\n",
    "    >>> EasyDict(None)\n",
    "    {}\n",
    "    >>> d = {'a': 1}\n",
    "    >>> EasyDict(**d)\n",
    "    {'a': 1}\n",
    "    Set attributes\n",
    "    >>> d = EasyDict()\n",
    "    >>> d.foo = 3\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar = {'prop': 'value'}\n",
    "    >>> d.bar.prop\n",
    "    'value'\n",
    "    >>> d\n",
    "    {'foo': 3, 'bar': {'prop': 'value'}}\n",
    "    >>> d.bar.prop = 'newer'\n",
    "    >>> d.bar.prop\n",
    "    'newer'\n",
    "    Values extraction\n",
    "    >>> d = EasyDict({'foo':0, 'bar':[{'x':1, 'y':2}, {'x':3, 'y':4}]})\n",
    "    >>> isinstance(d.bar, list)\n",
    "    True\n",
    "    >>> from operator import attrgetter\n",
    "    >>> map(attrgetter('x'), d.bar)\n",
    "    [1, 3]\n",
    "    >>> map(attrgetter('y'), d.bar)\n",
    "    [2, 4]\n",
    "    >>> d = EasyDict()\n",
    "    >>> d.keys()\n",
    "    []\n",
    "    >>> d = EasyDict(foo=3, bar=dict(x=1, y=2))\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar.x\n",
    "    1\n",
    "    Still like a dict though\n",
    "    >>> o = EasyDict({'clean':True})\n",
    "    >>> o.items()\n",
    "    [('clean', True)]\n",
    "    And like a class\n",
    "    >>> class Flower(EasyDict):\n",
    "    ...     power = 1\n",
    "    ...\n",
    "    >>> f = Flower()\n",
    "    >>> f.power\n",
    "    1\n",
    "    >>> f = Flower({'height': 12})\n",
    "    >>> f.height\n",
    "    12\n",
    "    >>> f['power']\n",
    "    1\n",
    "    >>> sorted(f.keys())\n",
    "    ['height', 'power']\n",
    "    update and pop items\n",
    "    >>> d = EasyDict(a=1, b='2')\n",
    "    >>> e = EasyDict(c=3.0, a=9.0)\n",
    "    >>> d.update(e)\n",
    "    >>> d.c\n",
    "    3.0\n",
    "    >>> d['c']\n",
    "    3.0\n",
    "    >>> d.get('c')\n",
    "    3.0\n",
    "    >>> d.update(a=4, b=4)\n",
    "    >>> d.b\n",
    "    4\n",
    "    >>> d.pop('a')\n",
    "    4\n",
    "    >>> d.a\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    AttributeError: 'EasyDict' object has no attribute 'a'\n",
    "    \"\"\"\n",
    "    def __init__(self, d=None, **kwargs):\n",
    "        if d is None:\n",
    "            d = {}\n",
    "        if kwargs:\n",
    "            d.update(**kwargs)\n",
    "        for k, v in d.items():\n",
    "            setattr(self, k, v)\n",
    "        # Class attributes\n",
    "        for k in self.__class__.__dict__.keys():\n",
    "            if not (k.startswith('__') and k.endswith('__')) and not k in ('update', 'pop'):\n",
    "                setattr(self, k, getattr(self, k))\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            value = [self.__class__(x)\n",
    "                     if isinstance(x, dict) else x for x in value]\n",
    "        elif isinstance(value, dict) and not isinstance(value, self.__class__):\n",
    "            value = self.__class__(value)\n",
    "        super(EasyDict, self).__setattr__(name, value)\n",
    "        super(EasyDict, self).__setitem__(name, value)\n",
    "\n",
    "    __setitem__ = __setattr__\n",
    "\n",
    "    def update(self, e=None, **f):\n",
    "        d = e or dict()\n",
    "        d.update(f)\n",
    "        for k in d:\n",
    "            setattr(self, k, d[k])\n",
    "\n",
    "    def pop(self, k, d=None):\n",
    "        delattr(self, k)\n",
    "        return super(EasyDict, self).pop(k, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_code = {\n",
    "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
    "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
    "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
    "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
    "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
    "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
    "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
    "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
    "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
    "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
    "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n",
    "    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n",
    "    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n",
    "    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n",
    "    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n",
    "    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n",
    "    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n",
    "    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n",
    "    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n",
    "    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n",
    "    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n",
    "    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n",
    "    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n",
    "    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n",
    "    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n",
    "    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n",
    "    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n",
    "    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n",
    "    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n",
    "    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n",
    "    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n",
    "    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n",
    "    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n",
    "    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n",
    "    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n",
    "    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n",
    "    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n",
    "    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n",
    "    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n",
    "    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n",
    "    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n",
    "    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n",
    "    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n",
    "    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n",
    "    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n",
    "    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n",
    "    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n",
    "    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n",
    "    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n",
    "    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n",
    "    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n",
    "    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n",
    "    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n",
    "}\n",
    "\n",
    "inv_bird_code = {v: k for k, v in bird_code.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X: np.ndarray,\n",
    "                  mean=None,\n",
    "                  std=None,\n",
    "                  norm_max=None,\n",
    "                  norm_min=None,\n",
    "                  eps=1e-6):\n",
    "    \"\"\"\n",
    "    Code from https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data\n",
    "    \"\"\"\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, cfg, clip):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.clip = clip\n",
    "        self.transforms = get_transforms(self.cfg)\n",
    "        self.is_train = cfg.is_train\n",
    "        self.sites = df['site'].values\n",
    "        self.row_ids = df['row_id'].values\n",
    "        self.seconds = df['seconds'].values\n",
    "        self.melspectrogram_parameters = {'n_mels': 128,\n",
    "                                                                        'fmin': 20,\n",
    "                                                                        'fmax': 16_000}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.row_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        SR = 32_000\n",
    "        site = self.sites[idx]\n",
    "        row_id = self.row_ids[idx]\n",
    "        \n",
    "        if site == 'site_3':\n",
    "            y = self.clip.astype(np.float32)\n",
    "            len_y = len(y)\n",
    "            start = 0\n",
    "            end = SR * 5\n",
    "            images = []\n",
    "            while len_y > start:\n",
    "                y_batch = y[start: end].astype(np.float32)\n",
    "                if len(y_batch) != (SR * 5):\n",
    "                    break\n",
    "                start = end\n",
    "                end += SR * 5\n",
    "                \n",
    "                melspec = librosa.feature.melspectrogram(y_batch,\n",
    "                                                                                           sr=SR,\n",
    "                                                                                           **self.melspectrogram_parameters)\n",
    "                melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "                image = mono_to_color(melspec)\n",
    "                \n",
    "                if self.transforms:\n",
    "                    image = self.transforms(image=image)['image']\n",
    "\n",
    "                image = cv2.resize(image, (self.cfg.img_size.height, self.cfg.img_size.width))\n",
    "                image = image.transpose(2, 0, 1).astype(np.float32)\n",
    "                image = (image / 255.0).astype(np.float32)\n",
    "                images.append(image)\n",
    "            \n",
    "            images = np.asarray(images)\n",
    "            return images, row_id, site\n",
    "        else:\n",
    "            end_seconds = int(self.seconds[idx])\n",
    "            start_seconds = int(end_seconds - 5)\n",
    "            \n",
    "            start_index = SR * start_seconds\n",
    "            end_index = SR * end_seconds\n",
    "            \n",
    "            y = self.clip[start_index:end_index].astype(np.float32)\n",
    "\n",
    "            melspec = librosa.feature.melspectrogram(y, sr=SR, **self.melspectrogram_parameters)\n",
    "            melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "            \n",
    "            image = mono_to_color(melspec)\n",
    "\n",
    "            if self.transforms:\n",
    "                image = self.transforms(image=image)['image']\n",
    "\n",
    "            image = cv2.resize(image, (self.cfg.img_size.height, self.cfg.img_size.width))\n",
    "            image = image.transpose(2, 0, 1).astype(np.float32)\n",
    "            image = (image / 255.0).astype(np.float32)\n",
    "            \n",
    "            return image, row_id, site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/bengaliai-cv19/discussion/123432\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "    \n",
    "    \n",
    "layer_encoder = {\n",
    "    'GeM': GeM,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplAtConv2d(Module):\n",
    "    \"\"\"Split-Attention Conv2d\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, channels, kernel_size, stride=(1, 1), padding=(0, 0),\n",
    "                 dilation=(1, 1), groups=1, bias=True,\n",
    "                 radix=2, reduction_factor=4,\n",
    "                 rectify=False, rectify_avg=False, norm_layer=None,\n",
    "                 dropblock_prob=0.0, **kwargs):\n",
    "        super(SplAtConv2d, self).__init__()\n",
    "        padding = _pair(padding)\n",
    "        self.rectify = rectify and (padding[0] > 0 or padding[1] > 0)\n",
    "        self.rectify_avg = rectify_avg\n",
    "        inter_channels = max(in_channels*radix//reduction_factor, 32)\n",
    "        self.radix = radix\n",
    "        self.cardinality = groups\n",
    "        self.channels = channels\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        if self.rectify:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv = RFConv2d(in_channels, channels*radix, kernel_size, stride, padding, dilation,\n",
    "                                 groups=groups*radix, bias=bias, average_mode=rectify_avg, **kwargs)\n",
    "        else:\n",
    "            self.conv = Conv2d(in_channels, channels*radix, kernel_size, stride, padding, dilation,\n",
    "                               groups=groups*radix, bias=bias, **kwargs)\n",
    "        self.use_bn = norm_layer is not None\n",
    "        if self.use_bn:\n",
    "            self.bn0 = norm_layer(channels*radix)\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc1 = Conv2d(channels, inter_channels, 1, groups=self.cardinality)\n",
    "        if self.use_bn:\n",
    "            self.bn1 = norm_layer(inter_channels)\n",
    "        self.fc2 = Conv2d(inter_channels, channels*radix, 1, groups=self.cardinality)\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock = DropBlock2D(dropblock_prob, 3)\n",
    "        self.rsoftmax = rSoftMax(radix, groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn0(x)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            x = self.dropblock(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        batch, rchannel = x.shape[:2]\n",
    "        if self.radix > 1:\n",
    "            splited = torch.split(x, rchannel//self.radix, dim=1)\n",
    "            gap = sum(splited) \n",
    "        else:\n",
    "            gap = x\n",
    "        gap = F.adaptive_avg_pool2d(gap, 1)\n",
    "        gap = self.fc1(gap)\n",
    "\n",
    "        if self.use_bn:\n",
    "            gap = self.bn1(gap)\n",
    "        gap = self.relu(gap)\n",
    "\n",
    "        atten = self.fc2(gap)\n",
    "        atten = self.rsoftmax(atten).view(batch, -1, 1, 1)\n",
    "\n",
    "        if self.radix > 1:\n",
    "            attens = torch.split(atten, rchannel//self.radix, dim=1)\n",
    "            out = sum([att*split for (att, split) in zip(attens, splited)])\n",
    "        else:\n",
    "            out = atten * x\n",
    "        return out.contiguous()\n",
    "\n",
    "class rSoftMax(nn.Module):\n",
    "    def __init__(self, radix, cardinality):\n",
    "        super().__init__()\n",
    "        self.radix = radix\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.size(0)\n",
    "        if self.radix > 1:\n",
    "            x = x.view(batch, self.cardinality, self.radix, -1).transpose(1, 2)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            x = x.reshape(batch, -1)\n",
    "        else:\n",
    "            x = torch.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_url_format = 'https://s3.us-west-1.wasabisys.com/resnest/torch/{}-{}.pth'\n",
    "\n",
    "_model_sha256 = {name: checksum for checksum, name in [\n",
    "    ('528c19ca', 'resnest50'),\n",
    "    ('22405ba7', 'resnest101'),\n",
    "    ('75117900', 'resnest200'),\n",
    "    ('0cc87c48', 'resnest269'),\n",
    "    ]}\n",
    "\n",
    "class DropBlock2D(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Global average pooling over the input's spatial dimensions\"\"\"\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return nn.functional.adaptive_avg_pool2d(inputs, 1).view(inputs.size(0), -1)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet Bottleneck\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-argument\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 radix=1, cardinality=1, bottleneck_width=64,\n",
    "                 avd=False, avd_first=False, dilation=1, is_first=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 norm_layer=None, dropblock_prob=0.0, last_gamma=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        group_width = int(planes * (bottleneck_width / 64.)) * cardinality\n",
    "        self.conv1 = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_layer(group_width)\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        self.radix = radix\n",
    "        self.avd = avd and (stride > 1 or is_first)\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        if self.avd:\n",
    "            self.avd_layer = nn.AvgPool2d(3, stride, padding=1)\n",
    "            stride = 1\n",
    "\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock1 = DropBlock2D(dropblock_prob, 3)\n",
    "            if radix == 1:\n",
    "                self.dropblock2 = DropBlock2D(dropblock_prob, 3)\n",
    "            self.dropblock3 = DropBlock2D(dropblock_prob, 3)\n",
    "\n",
    "        if radix >= 1:\n",
    "            self.conv2 = SplAtConv2d(\n",
    "                group_width, group_width, kernel_size=3,\n",
    "                stride=stride, padding=dilation,\n",
    "                dilation=dilation, groups=cardinality, bias=False,\n",
    "                radix=radix, rectify=rectified_conv,\n",
    "                rectify_avg=rectify_avg,\n",
    "                norm_layer=norm_layer,\n",
    "                dropblock_prob=dropblock_prob)\n",
    "        elif rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv2 = RFConv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False,\n",
    "                average_mode=rectify_avg)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            group_width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes*4)\n",
    "\n",
    "        if last_gamma:\n",
    "            from torch.nn.init import zeros_\n",
    "            zeros_(self.bn3.weight)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.avd and self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.radix == 0:\n",
    "            out = self.bn2(out)\n",
    "            if self.dropblock_prob > 0.0:\n",
    "                out = self.dropblock2(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "        if self.avd and not self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class FReLU(nn.Module):\n",
    "    r\"\"\" FReLU formulation. The funnel condition has a window size of kxk. (k=3 by default)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv_frelu = nn.Conv2d(in_channels, in_channels, 3, 1, 1, groups=in_channels)\n",
    "        self.bn_frelu = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_frelu(x)\n",
    "        x1 = self.bn_frelu(x1)\n",
    "        \n",
    "        x = torch.max(x, x1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bottleneck_frelu(nn.Module):\n",
    "    \"\"\"ResNet Bottleneck\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-argument\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 radix=1, cardinality=1, bottleneck_width=64,\n",
    "                 avd=False, avd_first=False, dilation=1, is_first=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 norm_layer=None, dropblock_prob=0.0, last_gamma=False):\n",
    "        super(Bottleneck_frelu, self).__init__()\n",
    "        group_width = int(planes * (bottleneck_width / 64.)) * cardinality\n",
    "        self.conv1 = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_layer(group_width)\n",
    "        self.frelu1 = FReLU(group_width)\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        self.radix = radix\n",
    "        self.avd = avd and (stride > 1 or is_first)\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        if self.avd:\n",
    "            self.avd_layer = nn.AvgPool2d(3, stride, padding=1)\n",
    "            stride = 1\n",
    "\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock1 = DropBlock2D(dropblock_prob, 3)\n",
    "            if radix == 1:\n",
    "                self.dropblock2 = DropBlock2D(dropblock_prob, 3)\n",
    "            self.dropblock3 = DropBlock2D(dropblock_prob, 3)\n",
    "\n",
    "        if radix >= 1:\n",
    "            self.conv2 = SplAtConv2d(\n",
    "                group_width, group_width, kernel_size=3,\n",
    "                stride=stride, padding=dilation,\n",
    "                dilation=dilation, groups=cardinality, bias=False,\n",
    "                radix=radix, rectify=rectified_conv,\n",
    "                rectify_avg=rectify_avg,\n",
    "                norm_layer=norm_layer,\n",
    "                dropblock_prob=dropblock_prob)\n",
    "        elif rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv2 = RFConv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False,\n",
    "                average_mode=rectify_avg)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "            self.frelu2 = FReLU(group_width)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "            self.frelu2 = FReLU(group_width)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            group_width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes*4)\n",
    "\n",
    "        if last_gamma:\n",
    "            from torch.nn.init import zeros_\n",
    "            zeros_(self.bn3.weight)\n",
    "        self.frelu3 = FReLU(planes*4)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock1(out)\n",
    "        out = self.frelu1(out)\n",
    "\n",
    "        if self.avd and self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.radix == 0:\n",
    "            out = self.bn2(out)\n",
    "            if self.dropblock_prob > 0.0:\n",
    "                out = self.dropblock2(out)\n",
    "            out = self.frelu2(out)\n",
    "\n",
    "        if self.avd and not self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.frelu3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"ResNet Variants\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : Block\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    dilated : bool, default False\n",
    "        Applying dilation strategy to pretrained ResNet yielding a stride-8 model,\n",
    "        typically used in Semantic Segmentation.\n",
    "    norm_layer : object\n",
    "        Normalization layer used in backbone network (default: :class:`mxnet.gluon.nn.BatchNorm`;\n",
    "        for Synchronized Cross-GPU BachNormalization).\n",
    "    Reference:\n",
    "        - He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n",
    "        - Yu, Fisher, and Vladlen Koltun. \"Multi-scale context aggregation by dilated convolutions.\"\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-variable\n",
    "    def __init__(self, block, layers, radix=1, groups=1, bottleneck_width=64,\n",
    "                 num_classes=1000, dilated=False, dilation=1,\n",
    "                 deep_stem=False, stem_width=64, avg_down=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 avd=False, avd_first=False,\n",
    "                 final_drop=0.0, dropblock_prob=0,\n",
    "                 last_gamma=False, norm_layer=nn.BatchNorm2d):\n",
    "        self.cardinality = groups\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        # ResNet-D params\n",
    "        self.inplanes = stem_width*2 if deep_stem else 64\n",
    "        self.avg_down = avg_down\n",
    "        self.last_gamma = last_gamma\n",
    "        # ResNeSt params\n",
    "        self.radix = radix\n",
    "        self.avd = avd\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        self.rectified_conv = rectified_conv\n",
    "        self.rectify_avg = rectify_avg\n",
    "        if rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            conv_layer = RFConv2d\n",
    "        else:\n",
    "            conv_layer = nn.Conv2d\n",
    "        conv_kwargs = {'average_mode': rectify_avg} if rectified_conv else {}\n",
    "        if deep_stem:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                conv_layer(3, stem_width, kernel_size=3, stride=2, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width*2, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = conv_layer(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False, **conv_kwargs)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], norm_layer=norm_layer, is_first=False)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n",
    "        if dilated or dilation == 4:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=4, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        elif dilation==2:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           dilation=1, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        else:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        self.avgpool = GlobalAvgPool2d()\n",
    "        self.drop = nn.Dropout(final_drop) if final_drop > 0.0 else None\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, norm_layer):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm_layer=None,\n",
    "                    dropblock_prob=0.0, is_first=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            down_layers = []\n",
    "            if self.avg_down:\n",
    "                if dilation == 1:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=stride, stride=stride,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                else:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=1, stride=1,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=1, bias=False))\n",
    "            else:\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=stride, bias=False))\n",
    "            down_layers.append(norm_layer(planes * block.expansion))\n",
    "            downsample = nn.Sequential(*down_layers)\n",
    "\n",
    "        layers = []\n",
    "        if dilation == 1 or dilation == 2:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=1, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        elif dilation == 4:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=2, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        else:\n",
    "            raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n",
    "\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=dilation, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.drop:\n",
    "            x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# https://github.com/zhanghang1989/ResNeSt/blob/master/resnest/torch/resnest.py\n",
    "def short_hash(name):\n",
    "    if name not in _model_sha256:\n",
    "        raise ValueError('Pretrained model for {name} is not available.'.format(name=name))\n",
    "    return _model_sha256[name][:8]\n",
    "\n",
    "resnest_model_urls = {name: _url_format.format(name, short_hash(name)) for\n",
    "    name in _model_sha256.keys()\n",
    "}\n",
    "\n",
    "\n",
    "def resnest50(pretrained=False, root='~/.encoding/models', **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3],\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=32, avg_down=True,\n",
    "                   avd=True, avd_first=False, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.hub.load_state_dict_from_url(\n",
    "            resnest_model_urls['resnest50'], progress=True, check_hash=True))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnest50_frelu(pretrained=False, root='~/.encoding/models', **kwargs):\n",
    "    model = ResNet(Bottleneck_frelu, [3, 4, 6, 3],\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=32, avg_down=True,\n",
    "                   avd=True, avd_first=False, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnest101(pretrained=False, root='~/.encoding/models', **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3],\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=64, avg_down=True,\n",
    "                   avd=True, avd_first=False, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.hub.load_state_dict_from_url(\n",
    "            resnest_model_urls['resnest101'], progress=True, check_hash=True))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnest200(pretrained=False, root='~/.encoding/models', **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 24, 36, 3],\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=64, avg_down=True,\n",
    "                   avd=True, avd_first=False, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.hub.load_state_dict_from_url(\n",
    "            resnest_model_urls['resnest200'], progress=True, check_hash=True))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnest269(pretrained=False, root='~/.encoding/models', **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 30, 48, 8],\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=64, avg_down=True,\n",
    "                   avd=True, avd_first=False, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.hub.load_state_dict_from_url(\n",
    "            resnest_model_urls['resnest269'], progress=True, check_hash=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = {\n",
    "    'resnest50': resnest50,\n",
    "    'resnest50_frelu': resnest50_frelu,\n",
    "    'resnest101': resnest101,\n",
    "    'resnest200': resnest200,\n",
    "    'resnest269': resnest269\n",
    "}\n",
    "\n",
    "\n",
    "def set_channels(child, cfg):\n",
    "    if cfg.model.n_channels < 3:\n",
    "        child_weight = child.weight.data[:, :cfg.model.n_channels, :, :]\n",
    "    else:\n",
    "        child_weight = torch.cat([child.weight.data[:, :, :, :], child.weight.data[:, :int(cfg.model.n_channels - 3), :, :]], dim=1)\n",
    "    setattr(child, 'in_channels', cfg.model.n_channels)\n",
    "\n",
    "    if cfg.model.pretrained:\n",
    "        setattr(child.weight, 'data', child_weight)\n",
    "\n",
    "\n",
    "def replace_channels(model, cfg):\n",
    "    if cfg.model.name.startswith('densenet'):\n",
    "        set_channels(model.features[0], cfg)\n",
    "    elif cfg.model.name.startswith('efficientnet'):\n",
    "        set_channels(model._conv_stem, cfg)\n",
    "    elif cfg.model.name.startswith('mobilenet'):\n",
    "        set_channels(model.features[0][0], cfg)\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        set_channels(model.layer0.conv1, cfg)\n",
    "    elif cfg.model.name.startswith('resnet') or cfg.model.name.startswith('resnex') or cfg.model.name.startswith('wide_resnet'):\n",
    "        set_channels(model.conv1, cfg)\n",
    "    elif cfg.model.name.startswith('resnest'):\n",
    "        set_channels(model.conv1[0], cfg)\n",
    "    elif cfg.model.name.startswith('ghostnet'):\n",
    "        set_channels(model.features[0][0], cfg)\n",
    "\n",
    "\n",
    "def get_head(cfg):\n",
    "    head_modules = []\n",
    "    \n",
    "    for m in cfg.values():\n",
    "        if hasattr(nn, m['name']):\n",
    "            module = getattr(nn, m['name'])(**m['params'])\n",
    "        elif m['name'] in layer_encoder:\n",
    "            module = layer_encoder[m['name']](**m['params'])\n",
    "        head_modules.append(module)\n",
    "\n",
    "    head_modules = nn.Sequential(*head_modules)\n",
    "    \n",
    "    return head_modules\n",
    "\n",
    "\n",
    "def replace_fc(model, cfg):\n",
    "    if cfg.model.metric:\n",
    "        classes = 1000\n",
    "    else:\n",
    "        classes = cfg.model.n_classes\n",
    "\n",
    "    if cfg.model.name.startswith('densenet'):\n",
    "        model.classifier = get_head(cfg.model.head)\n",
    "    elif cfg.model.name.startswith('efficientnet'):\n",
    "        model._fc = get_head(cfg.model.head)\n",
    "    elif cfg.model.name.startswith('mobilenet'):\n",
    "        model.classifier[1] = get_head(cfg.model.head)\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        model.last_linear = get_head(cfg.model.head)\n",
    "    elif (cfg.model.name.startswith('resnet') or\n",
    "          cfg.model.name.startswith('resnex') or\n",
    "          cfg.model.name.startswith('wide_resnet') or\n",
    "          cfg.model.name.startswith('resnest')):\n",
    "        model.fc = get_head(cfg.model.head)\n",
    "    elif cfg.model.name.startswith('ghostnet'):\n",
    "        model.classifier = get_head(cfg.model.head)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def replace_pool(model, cfg):\n",
    "    avgpool = layer_encoder[cfg.model.avgpool.name](**cfg.model.avgpool.params)\n",
    "    if cfg.model.name.startswith('efficientnet'):\n",
    "        model._avg_pooling = avgpool\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        model.avg_pool = avgpool\n",
    "    elif (cfg.model.name.startswith('resnet') or\n",
    "          cfg.model.name.startswith('resnex') or\n",
    "          cfg.model.name.startswith('wide_resnet') or\n",
    "          cfg.model.name.startswith('resnest')):\n",
    "        model.avgpool = avgpool\n",
    "    elif cfg.model.name.startswith('ghostnet'):\n",
    "        model.squeeze[-1] = avgpool\n",
    "    return model\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.base_model = model_encoder[cfg.model.name](pretrained=False)\n",
    "        if cfg.model.n_channels != 3:\n",
    "            replace_channels(self.base_model, cfg)\n",
    "        if cfg.model.avgpool:\n",
    "            self.base_model = replace_pool(self.base_model, cfg)\n",
    "        self.model = replace_fc(self.base_model, cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(cfg, is_train=True):\n",
    "    model = CustomModel(cfg)\n",
    "\n",
    "    if cfg.model.multi_gpu and is_train:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_loss(cfg):\n",
    "    loss_ = getattr(loss, cfg.loss.name)(**cfg.loss.params)\n",
    "    return loss_\n",
    "\n",
    "\n",
    "def get_dataloader(df, cfg, clip):\n",
    "    dataset = CustomDataset(df, cfg, clip)\n",
    "    loader = DataLoader(dataset, **cfg.loader)\n",
    "    return loader\n",
    "\n",
    "\n",
    "def get_optim(cfg, parameters):\n",
    "    optim = getattr(torch.optim, cfg.optimizer.name)(params=parameters, **cfg.optimizer.params)\n",
    "    return optim\n",
    "\n",
    "\n",
    "def get_scheduler(cfg, optimizer):\n",
    "    if cfg.scheduler.name == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            **cfg.scheduler.params,\n",
    "        )\n",
    "    else:\n",
    "        scheduler = getattr(torch.optim.lr_scheduler, cfg.scheduler.name)(\n",
    "            optimizer,\n",
    "            **cfg.scheduler.params,\n",
    "        )\n",
    "    return scheduler\n",
    "\n",
    "\n",
    "def get_transforms(cfg):\n",
    "    def get_object(transform):\n",
    "        if hasattr(album, transform.name):\n",
    "            return getattr(album, transform.name)\n",
    "        elif hasattr(custom_album, transform.name):\n",
    "            return getattr(custom_album, transform.name)\n",
    "        else:\n",
    "            return eval(transform.name)\n",
    "    if cfg.transforms:\n",
    "        transforms = [get_object(transform)(**transform.params) for name, transform in cfg.transforms.items()]\n",
    "        return album.Compose(transforms)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_fold(cfg, df, target):\n",
    "    df_ = df.copy()\n",
    "    target_columns = target.columns[0]\n",
    "    df_[target_columns] = target[target_columns].values\n",
    "\n",
    "    fold_df = pd.DataFrame(index=range(len(df_)))\n",
    "\n",
    "    if len(cfg.weight) == 1:\n",
    "        weight_list = [cfg.weight[0] for i in range(cfg.params.n_splits)]\n",
    "    else:\n",
    "        weight_list = cfg.weight\n",
    "\n",
    "    fold = getattr(validation, cfg.name)(cfg)\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(fold.split(df_)):\n",
    "        fold_df[f'fold_{fold_}'] = 0\n",
    "        fold_df.loc[val_idx, f'fold_{fold_}'] = weight_list[fold_]\n",
    "    \n",
    "    return fold_df\n",
    "\n",
    "\n",
    "def get_metrics(cfg):\n",
    "    evaluator = getattr(metrics, cfg)\n",
    "    return evaluator\n",
    "\n",
    "\n",
    "def fill_dropped(dropped_array, drop_idx):\n",
    "    filled_array = np.zeros(len(dropped_array) + len(drop_idx))\n",
    "    idx_array = np.arange(len(filled_array))\n",
    "    use_idx = np.delete(idx_array, drop_idx)\n",
    "    filled_array[use_idx] = dropped_array\n",
    "    return filled_array\n",
    "\n",
    "\n",
    "def get_drop_idx(cfg):\n",
    "    drop_idx_list = []\n",
    "    for drop_name in cfg:\n",
    "        drop_idx = np.load(f'../pickle/{drop_name}.npy')\n",
    "        drop_idx_list.append(drop_idx)\n",
    "    all_drop_idx = np.unique(np.concatenate(drop_idx_list))\n",
    "    return all_drop_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def prediction_for_clip(test_df, clip, model, cfg, threshold=0.5):\n",
    "    test_loader = get_dataloader(test_df, cfg.data.test, clip)\n",
    "    \n",
    "    model.eval()\n",
    "    prediction_dict = {}\n",
    "    for i, (image, row_id, site) in enumerate(test_loader):\n",
    "        site = site[0]\n",
    "        row_id = row_id[0]\n",
    "\n",
    "        if site in {\"site_1\", \"site_2\"}:\n",
    "            image = Variable(image).to(device)\n",
    "            with torch.no_grad():\n",
    "                preds = F.sigmoid(model(image.float()))\n",
    "                preds = preds.cpu().detach().numpy().reshape(-1)\n",
    "            events = preds >= threshold\n",
    "            labels = np.argwhere(events).reshape(-1).tolist()\n",
    "\n",
    "        else:\n",
    "            image = image.squeeze(0)\n",
    "            batch_size = 16\n",
    "            whole_size = image.size(0)\n",
    "            if whole_size % batch_size == 0:\n",
    "                n_iter = whole_size // batch_size\n",
    "            else:\n",
    "                n_iter = whole_size // batch_size + 1\n",
    "\n",
    "            all_events = set()\n",
    "            for batch_i in range(n_iter):\n",
    "                batch = image[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "                if batch.ndim == 3:\n",
    "                    batch = batch.unsqueeze(0)\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    preds = F.sigmoid(model(batch))\n",
    "                    preds = preds.cpu().detach().numpy()\n",
    "\n",
    "                events = preds >= threshold\n",
    "                for i in range(len(events)):\n",
    "                    event = events[i, :]\n",
    "                    labels = np.argwhere(event).reshape(-1).tolist()\n",
    "                    for label in labels:\n",
    "                        all_events.add(label)\n",
    "                \n",
    "                labels = list(all_events)\n",
    "        if len(labels) == 0:\n",
    "            prediction_dict[row_id] = 'nocall'\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: inv_bird_code[x], labels))\n",
    "            label_string = ' '.join(labels_str_list)\n",
    "            prediction_dict[row_id] = label_string\n",
    "    return prediction_dict\n",
    "\n",
    "\n",
    "def prediction(test_df, test_audio_dir, target_sr, cfg, log_path):\n",
    "    model = get_model(cfg, is_train=False).to(device)\n",
    "    model.load_state_dict(torch.load(f'{str(log_path)}/weight_best_0.pt'))\n",
    "    \n",
    "    unique_audio_id = test_df['audio_id'].unique()\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "    for audio_id in unique_audio_id:\n",
    "        clip, _ = librosa.load(str(test_audio_dir / f'{audio_id}.mp3'),\n",
    "                                            sr=target_sr,\n",
    "                                            mono=True,\n",
    "                                            res_type=\"kaiser_fast\")\n",
    "        test_df_for_audio_id = test_df[test_df['audio_id'] == audio_id]\n",
    "        prediction_dict = prediction_for_clip(test_df_for_audio_id,\n",
    "                                                                         clip=clip,\n",
    "                                                                         model=model,\n",
    "                                                                         cfg=cfg,\n",
    "                                                                         threshold=0.7)\n",
    "        row_id = list(prediction_dict.keys())\n",
    "        birds = list(prediction_dict.values())\n",
    "        prediction_df = pd.DataFrame({\n",
    "                \"row_id\": row_id,\n",
    "                \"birds\": birds\n",
    "        })\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    \n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/kaggle/input/birdsong-recognition/')\n",
    "data_dir = root / 'test_audio'\n",
    "save_resample_dir = Path('/kaggle/test_audio_resample')\n",
    "save_mel_dir = Path('/kaggle/test_audio_mel')\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    test_df = pd.read_csv('/kaggle/input/birdcall-check/test.csv')\n",
    "    data_dir = Path('/kaggle/input/birdcall-check/test_audio')\n",
    "else:\n",
    "    test_df = pd.read_csv(root / 'test.csv')\n",
    "    \n",
    "test_audio_infos = test_df[['audio_id', 'site', 'seconds']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = Path(glob.glob('/kaggle/input/sub-*')[0])\n",
    "\n",
    "with open(log_path / 'config.yml', 'r') as yf:\n",
    "    cfg = EasyDict(yaml.safe_load(yf))\n",
    "\n",
    "TARGET_SR = 32000\n",
    "\n",
    "sub_df = prediction(test_df=test_df, \n",
    "                                   test_audio_dir=data_dir, \n",
    "                                   target_sr=TARGET_SR,\n",
    "                                   cfg=cfg,\n",
    "                                   log_path=log_path)\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "sub_df['birds'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
